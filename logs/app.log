2023-04-15 17:00:23,079 [INFO] Training started
2023-04-15 17:00:23,233 [INFO] Using cuda
2023-04-15 17:00:24,817 [INFO] Loaded CIFAR10
2023-04-15 17:00:24,843 [INFO] Training indices read from params/train_idx.csv
2023-04-15 17:00:24,846 [INFO] Validation indices read from params/val_idx.csv
2023-04-15 17:00:25,623 [INFO] Loaded VGG16 with default pretrained weights
2023-04-15 17:00:25,624 [INFO] Classifier modified to 10 classes
2023-04-15 17:00:30,056 [INFO] Loaded optimizer ADAM with default parameters
2023-04-15 17:00:30,056 [INFO] Loaded Cross Entropy Loss
2023-04-15 17:00:30,057 [INFO] Loaded LR scheduler
2023-04-15 17:00:30,450 [INFO] Read supporting modules base weights
2023-04-16 13:04:00,423 [INFO] Training started
2023-04-16 13:04:00,680 [INFO] Using cuda
2023-04-16 13:04:02,630 [INFO] Loaded CIFAR10
2023-04-16 13:04:02,821 [INFO] Generated 5 splits - 12.5% validation set
2023-04-16 13:04:02,930 [INFO] Training indices read from params/train_idx.csv
2023-04-16 13:04:02,934 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 13:04:05,092 [INFO] Loaded VGG16 with default pretrained weights
2023-04-16 13:04:05,093 [INFO] Classifier modified to 10 classes
2023-04-16 13:04:12,522 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 13:04:12,524 [INFO] Classifier modified to 10 classes
2023-04-16 13:04:12,593 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 13:04:12,593 [INFO] Loaded Cross Entropy Loss
2023-04-16 13:04:12,594 [INFO] Loaded LR scheduler
2023-04-16 13:04:12,880 [INFO] Generated supporting modules base weights
2023-04-16 13:04:13,157 [INFO] Read supporting modules base weights
2023-04-16 13:04:13,211 [INFO] Used supporting modules base weights
2023-04-16 13:04:13,212 [INFO] Training on 43750 samples
2023-04-16 13:05:55,287 [INFO] Sub epoch 0 train acc: 37.40 train loss: 0.1146 val acc: 43.95 val loss: 1.6504
2023-04-16 13:07:21,595 [INFO] Sub epoch 1 train acc: 39.50 train loss: 0.1112 val acc: 44.29 val loss: 29.3740
2023-04-16 13:08:48,710 [INFO] Sub epoch 2 train acc: 39.77 train loss: 0.1115 val acc: 42.48 val loss: 42.7815
2023-04-16 13:09:04,141 [INFO] Used supporting modules base weights
2023-04-16 13:09:04,141 [INFO] Training on 43750 samples
2023-04-16 13:10:30,015 [INFO] Sub epoch 0 train acc: 37.38 train loss: 0.1147 val acc: 42.32 val loss: 29.8860
2023-04-16 13:11:57,520 [INFO] Sub epoch 1 train acc: 40.04 train loss: 0.1108 val acc: 44.72 val loss: 0.2900
2023-04-16 13:13:25,156 [INFO] Sub epoch 2 train acc: 39.96 train loss: 0.1115 val acc: 43.74 val loss: 1.2216
2023-04-16 13:19:46,319 [INFO] Training started
2023-04-16 13:19:46,439 [INFO] Using cuda
2023-04-16 13:19:48,239 [INFO] Loaded CIFAR10
2023-04-16 13:19:48,277 [INFO] Training indices read from params/train_idx.csv
2023-04-16 13:19:48,282 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 13:19:49,249 [INFO] Loaded VGG16 with default pretrained weights
2023-04-16 13:19:49,250 [INFO] Classifier modified to 10 classes
2023-04-16 13:19:56,670 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 13:19:56,672 [INFO] Classifier modified to 10 classes
2023-04-16 13:19:56,729 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 13:19:56,729 [INFO] Loaded Cross Entropy Loss
2023-04-16 13:19:56,729 [INFO] Loaded LR scheduler
2023-04-16 13:19:57,011 [INFO] Read supporting modules base weights
2023-04-16 13:19:57,043 [INFO] Used supporting modules base weights
2023-04-16 13:19:57,043 [INFO] Training on 43750 samples
2023-04-16 13:20:36,962 [INFO] Sub epoch 0 train acc: 40.44 train loss: 0.0276 val acc: 49.26 val loss: 0.3519
2023-04-16 13:21:00,600 [INFO] Sub epoch 1 train acc: 44.52 train loss: 0.0258 val acc: 50.00 val loss: 0.2917
2023-04-16 13:21:23,640 [INFO] Sub epoch 2 train acc: 44.78 train loss: 0.0257 val acc: 51.44 val loss: 0.4943
2023-04-16 13:21:27,824 [INFO] Used supporting modules base weights
2023-04-16 13:21:27,824 [INFO] Training on 43750 samples
2023-04-16 13:21:50,177 [INFO] Sub epoch 0 train acc: 40.61 train loss: 0.0276 val acc: 50.18 val loss: 0.0249
2023-04-16 13:22:13,173 [INFO] Sub epoch 1 train acc: 44.52 train loss: 0.0259 val acc: 50.64 val loss: 0.0243
2023-04-16 13:22:35,427 [INFO] Sub epoch 2 train acc: 44.87 train loss: 0.0256 val acc: 50.98 val loss: 0.3116
2023-04-16 14:13:45,763 [INFO] Training started
2023-04-16 14:13:45,919 [INFO] Using cuda
2023-04-16 14:13:47,851 [INFO] Loaded CIFAR10
2023-04-16 14:13:47,903 [INFO] Training indices read from params/train_idx.csv
2023-04-16 14:13:47,908 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 14:13:48,586 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 14:13:48,588 [INFO] Classifier modified to 10 classes
2023-04-16 14:13:55,939 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 14:13:55,940 [INFO] Loaded Cross Entropy Loss
2023-04-16 14:13:55,940 [INFO] Loaded LR scheduler
2023-04-16 14:13:56,432 [INFO] Read supporting modules base weights
2023-04-16 14:13:56,502 [INFO] Used supporting modules base weights
2023-04-16 14:13:56,503 [INFO] Training on 43750 samples
2023-04-16 14:14:37,332 [INFO] Sub epoch 0 train acc: 39.97 train loss: 0.0277 val acc: 48.66 val loss: 0.2020
2023-04-16 14:15:01,494 [INFO] Sub epoch 1 train acc: 44.55 train loss: 0.0258 val acc: 50.98 val loss: 0.2234
2023-04-16 14:15:24,377 [INFO] Sub epoch 2 train acc: 44.77 train loss: 0.0256 val acc: 51.78 val loss: 0.3350
2023-04-16 14:15:28,207 [INFO] Train Loss: 0.0256, Train Acc: 44.77,  Validation Loss: 0.3350, Validation Acc: 51.78
2023-04-16 14:15:28,225 [INFO] Used supporting modules base weights
2023-04-16 14:15:28,225 [INFO] Training on 43750 samples
2023-04-16 14:15:50,892 [INFO] Sub epoch 0 train acc: 40.43 train loss: 0.0276 val acc: 50.24 val loss: 0.0257
2023-04-16 14:16:13,079 [INFO] Sub epoch 1 train acc: 44.56 train loss: 0.0259 val acc: 50.46 val loss: 0.0272
2023-04-16 14:16:35,690 [INFO] Sub epoch 2 train acc: 45.24 train loss: 0.0255 val acc: 51.57 val loss: 0.0240
2023-04-16 14:16:39,499 [INFO] Train Loss: 0.0255, Train Acc: 45.24,  Validation Loss: 0.0240, Validation Acc: 51.57
2023-04-16 16:05:47,711 [INFO] Training started
2023-04-16 16:05:47,929 [INFO] Using cuda
2023-04-16 16:05:49,854 [INFO] Loaded CIFAR10
2023-04-16 16:05:49,901 [INFO] Training indices read from params/train_idx.csv
2023-04-16 16:05:49,906 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 16:05:50,609 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 16:05:50,611 [INFO] Classifier modified to 10 classes
2023-04-16 16:05:58,174 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 16:05:58,175 [INFO] Loaded Cross Entropy Loss
2023-04-16 16:05:58,175 [INFO] Loaded LR scheduler
2023-04-16 16:05:58,614 [INFO] Read supporting modules base weights
2023-04-16 16:05:58,650 [INFO] Used supporting modules base weights
2023-04-16 16:05:58,651 [INFO] Training on 43750 samples
2023-04-16 16:06:30,440 [INFO] Sub epoch 0 train acc: 40.11 train loss: 0.0139 val acc: 50.19 val loss: 0.0124
2023-04-16 16:06:41,602 [INFO] Sub epoch 1 train acc: 45.65 train loss: 0.0127 val acc: 51.17 val loss: 0.0119
2023-04-16 16:06:53,884 [INFO] Sub epoch 2 train acc: 46.31 train loss: 0.0125 val acc: 51.74 val loss: 0.0178
2023-04-16 16:06:56,230 [INFO] Train Loss: 0.0125, Train Acc: 46.31,  Validation Loss: 0.0178, Validation Acc: 51.74
2023-04-16 16:06:56,248 [INFO] Used supporting modules base weights
2023-04-16 16:06:56,248 [INFO] Training on 43750 samples
2023-04-16 16:07:08,376 [INFO] Sub epoch 0 train acc: 40.04 train loss: 0.0139 val acc: 51.76 val loss: 0.0118
2023-04-16 16:07:20,510 [INFO] Sub epoch 1 train acc: 45.43 train loss: 0.0128 val acc: 52.21 val loss: 0.0116
2023-04-16 16:07:32,315 [INFO] Sub epoch 2 train acc: 46.11 train loss: 0.0126 val acc: 52.45 val loss: 0.0112
2023-04-16 16:07:34,138 [INFO] Train Loss: 0.0126, Train Acc: 46.11,  Validation Loss: 0.0112, Validation Acc: 52.45
2023-04-16 16:12:45,028 [INFO] Training started
2023-04-16 16:12:45,040 [INFO] Using cuda
2023-04-16 16:12:47,015 [INFO] Loaded CIFAR10
2023-04-16 16:12:47,059 [INFO] Training indices read from params/train_idx.csv
2023-04-16 16:12:47,065 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 16:12:47,619 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 16:12:47,621 [INFO] Classifier modified to 10 classes
2023-04-16 16:12:54,627 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 16:12:54,628 [INFO] Loaded Cross Entropy Loss
2023-04-16 16:12:54,628 [INFO] Loaded LR scheduler
2023-04-16 16:12:55,061 [INFO] Read supporting modules base weights
2023-04-16 16:12:55,087 [INFO] Used supporting modules base weights
2023-04-16 16:12:55,087 [INFO] Training on 43750 samples
2023-04-16 16:13:18,244 [INFO] Sub epoch 0 train acc: 38.69 train loss: 0.0072 val acc: 49.47 val loss: 0.0062
2023-04-16 16:13:25,214 [INFO] Sub epoch 1 train acc: 45.96 train loss: 0.0064 val acc: 52.24 val loss: 0.0058
2023-04-16 16:13:31,390 [INFO] Sub epoch 2 train acc: 46.56 train loss: 0.0063 val acc: 52.58 val loss: 0.0135
2023-04-16 16:13:33,079 [INFO] Train Loss: 0.0063, Train Acc: 46.56,  Validation Loss: 0.0135, Validation Acc: 52.58
2023-04-16 16:13:33,123 [INFO] Used supporting modules base weights
2023-04-16 16:13:33,123 [INFO] Training on 43750 samples
2023-04-16 16:13:39,262 [INFO] Sub epoch 0 train acc: 38.21 train loss: 0.0072 val acc: 50.61 val loss: 0.0062
2023-04-16 16:13:45,525 [INFO] Sub epoch 1 train acc: 45.86 train loss: 0.0064 val acc: 51.74 val loss: 0.0059
2023-04-16 16:13:52,046 [INFO] Sub epoch 2 train acc: 46.91 train loss: 0.0062 val acc: 52.13 val loss: 0.0058
2023-04-16 16:13:53,584 [INFO] Train Loss: 0.0062, Train Acc: 46.91,  Validation Loss: 0.0058, Validation Acc: 52.13
2023-04-16 16:15:03,452 [INFO] Training started
2023-04-16 16:15:03,465 [INFO] Using cuda
2023-04-16 16:15:05,280 [INFO] Loaded CIFAR10
2023-04-16 16:15:05,317 [INFO] Training indices read from params/train_idx.csv
2023-04-16 16:15:05,321 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 16:15:05,735 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 16:15:05,736 [INFO] Classifier modified to 10 classes
2023-04-16 16:15:12,017 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 16:15:12,018 [INFO] Loaded Cross Entropy Loss
2023-04-16 16:15:12,018 [INFO] Loaded LR scheduler
2023-04-16 16:15:12,285 [INFO] Read supporting modules base weights
2023-04-16 16:15:12,311 [INFO] Used supporting modules base weights
2023-04-16 16:15:12,311 [INFO] Training on 43750 samples
2023-04-16 16:15:31,231 [INFO] Sub epoch 0 train acc: 36.41 train loss: 0.0037 val acc: 49.44 val loss: 0.0033
2023-04-16 16:15:36,530 [INFO] Sub epoch 1 train acc: 45.11 train loss: 0.0033 val acc: 51.78 val loss: 0.0031
2023-04-16 16:15:41,756 [INFO] Sub epoch 2 train acc: 46.44 train loss: 0.0032 val acc: 52.11 val loss: 0.0030
2023-04-16 16:15:43,651 [INFO] Train Loss: 0.0032, Train Acc: 46.44,  Validation Loss: 0.0030, Validation Acc: 52.11
2023-04-16 16:15:43,669 [INFO] Used supporting modules base weights
2023-04-16 16:15:43,669 [INFO] Training on 43750 samples
2023-04-16 16:15:48,889 [INFO] Sub epoch 0 train acc: 35.92 train loss: 0.0037 val acc: 48.83 val loss: 0.0033
2023-04-16 16:15:53,953 [INFO] Sub epoch 1 train acc: 44.76 train loss: 0.0033 val acc: 50.90 val loss: 0.0031
2023-04-16 16:15:59,146 [INFO] Sub epoch 2 train acc: 46.14 train loss: 0.0032 val acc: 52.11 val loss: 0.0030
2023-04-16 16:16:00,503 [INFO] Train Loss: 0.0032, Train Acc: 46.14,  Validation Loss: 0.0030, Validation Acc: 52.11
2023-04-16 16:20:52,424 [INFO] Training started
2023-04-16 16:20:52,438 [INFO] Using cuda
2023-04-16 16:20:54,230 [INFO] Loaded CIFAR10
2023-04-16 16:20:54,268 [INFO] Training indices read from params/train_idx.csv
2023-04-16 16:20:54,273 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 16:20:54,703 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 16:20:54,705 [INFO] Classifier modified to 10 classes
2023-04-16 16:21:00,479 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 16:21:00,480 [INFO] Loaded Cross Entropy Loss
2023-04-16 16:21:00,480 [INFO] Loaded LR scheduler
2023-04-16 16:21:00,722 [INFO] Read supporting modules base weights
2023-04-16 16:21:00,759 [INFO] Used supporting modules base weights
2023-04-16 16:21:00,759 [INFO] Training on 43750 samples
2023-04-16 16:21:32,479 [INFO] Sub epoch 0 train acc: 26.61 train loss: 0.0011 val acc: 44.98 val loss: 0.0011
2023-04-16 16:21:39,199 [INFO] Sub epoch 1 train acc: 39.77 train loss: 0.0009 val acc: 47.14 val loss: 0.0010
2023-04-16 16:21:45,757 [INFO] Sub epoch 2 train acc: 43.23 train loss: 0.0009 val acc: 49.30 val loss: 0.0010
2023-04-16 16:21:50,711 [INFO] Train Loss: 0.0009, Train Acc: 43.23,  Validation Loss: 0.0010, Validation Acc: 49.30
2023-04-16 16:21:50,763 [INFO] Used supporting modules base weights
2023-04-16 16:21:50,763 [INFO] Training on 43750 samples
2023-04-16 16:21:57,332 [INFO] Sub epoch 0 train acc: 26.95 train loss: 0.0011 val acc: 45.38 val loss: 0.0012
2023-04-16 16:22:03,846 [INFO] Sub epoch 1 train acc: 39.42 train loss: 0.0009 val acc: 48.19 val loss: 0.0011
2023-04-16 16:22:10,305 [INFO] Sub epoch 2 train acc: 43.28 train loss: 0.0009 val acc: 49.44 val loss: 0.0010
2023-04-16 16:22:12,070 [INFO] Train Loss: 0.0009, Train Acc: 43.28,  Validation Loss: 0.0010, Validation Acc: 49.44
2023-04-16 16:39:38,787 [INFO] Training started
2023-04-16 16:39:38,834 [INFO] Using cuda
2023-04-16 16:39:40,679 [INFO] Loaded CIFAR10
2023-04-16 16:39:40,717 [INFO] Training indices read from params/train_idx.csv
2023-04-16 16:39:40,721 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 16:39:41,259 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 16:39:41,261 [INFO] Classifier modified to 10 classes
2023-04-16 16:39:48,240 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 16:39:48,240 [INFO] Loaded Cross Entropy Loss
2023-04-16 16:39:48,240 [INFO] Loaded LR scheduler
2023-04-16 16:39:48,606 [INFO] Read supporting modules base weights
2023-04-16 16:39:48,632 [INFO] Used supporting modules base weights
2023-04-16 16:39:48,632 [INFO] Training on 43750 samples
2023-04-16 16:40:13,029 [INFO] Sub epoch 0 train acc: 39.03 train loss: 0.0071 val acc: 49.66 val loss: 0.0032
2023-04-16 16:40:13,030 [INFO] Saving best model with val_acc: 49.664
2023-04-16 16:40:19,443 [INFO] Sub epoch 1 train acc: 45.68 train loss: 0.0064 val acc: 51.66 val loss: 0.0032
2023-04-16 16:40:19,443 [INFO] Saving best model with val_acc: 51.664
2023-04-16 16:40:26,344 [INFO] Sub epoch 2 train acc: 46.90 train loss: 0.0062 val acc: 52.59 val loss: 0.0030
2023-04-16 16:40:26,345 [INFO] Saving best model with val_acc: 52.592
2023-04-16 16:40:32,729 [INFO] Sub epoch 3 train acc: 47.47 train loss: 0.0062 val acc: 52.45 val loss: 0.0030
2023-04-16 16:40:38,990 [INFO] Sub epoch 4 train acc: 47.45 train loss: 0.0062 val acc: 52.45 val loss: 0.0030
2023-04-16 16:40:45,613 [INFO] Sub epoch 5 train acc: 47.14 train loss: 0.0062 val acc: 52.96 val loss: 0.0029
2023-04-16 16:40:45,614 [INFO] Saving best model with val_acc: 52.96
2023-04-16 16:40:52,273 [INFO] Sub epoch 6 train acc: 47.47 train loss: 0.0061 val acc: 53.50 val loss: 0.0029
2023-04-16 16:40:52,273 [INFO] Saving best model with val_acc: 53.504
2023-04-16 16:40:58,679 [INFO] Sub epoch 7 train acc: 47.21 train loss: 0.0062 val acc: 52.78 val loss: 0.0029
2023-04-16 16:41:05,179 [INFO] Sub epoch 8 train acc: 47.33 train loss: 0.0062 val acc: 52.99 val loss: 0.0030
2023-04-16 16:41:11,734 [INFO] Sub epoch 9 train acc: 47.38 train loss: 0.0062 val acc: 53.90 val loss: 0.0029
2023-04-16 16:41:11,734 [INFO] Saving best model with val_acc: 53.904
2023-04-16 16:41:18,241 [INFO] Sub epoch 10 train acc: 47.61 train loss: 0.0061 val acc: 53.73 val loss: 0.0029
2023-04-16 16:41:24,461 [INFO] Sub epoch 11 train acc: 47.37 train loss: 0.0061 val acc: 53.31 val loss: 0.0029
2023-04-16 16:41:30,363 [INFO] Sub epoch 12 train acc: 47.50 train loss: 0.0061 val acc: 52.88 val loss: 0.0029
2023-04-16 16:41:36,664 [INFO] Sub epoch 13 train acc: 47.38 train loss: 0.0062 val acc: 53.28 val loss: 0.0029
2023-04-16 16:41:42,849 [INFO] Sub epoch 14 train acc: 47.78 train loss: 0.0061 val acc: 52.93 val loss: 0.0029
2023-04-16 16:41:49,207 [INFO] Sub epoch 15 train acc: 47.88 train loss: 0.0061 val acc: 53.46 val loss: 0.0029
2023-04-16 16:41:55,667 [INFO] Sub epoch 16 train acc: 47.84 train loss: 0.0061 val acc: 53.18 val loss: 0.0029
2023-04-16 16:42:02,163 [INFO] Sub epoch 17 train acc: 47.79 train loss: 0.0061 val acc: 53.81 val loss: 0.0040
2023-04-16 16:42:08,445 [INFO] Sub epoch 18 train acc: 47.58 train loss: 0.0061 val acc: 53.73 val loss: 0.0029
2023-04-16 16:42:15,021 [INFO] Sub epoch 19 train acc: 47.73 train loss: 0.0061 val acc: 53.60 val loss: 0.0029
2023-04-16 16:42:16,907 [INFO] Train Loss: 0.0061, Train Acc: 47.73,  Validation Loss: 0.0029, Validation Acc: 53.60
2023-04-16 16:42:16,928 [INFO] Used supporting modules base weights
2023-04-16 16:42:16,928 [INFO] Training on 43750 samples
2023-04-16 16:42:23,194 [INFO] Sub epoch 0 train acc: 38.72 train loss: 0.0072 val acc: 49.23 val loss: 0.0032
2023-04-16 16:42:23,194 [INFO] Saving best model with val_acc: 49.232
2023-04-16 16:42:29,795 [INFO] Sub epoch 1 train acc: 45.79 train loss: 0.0064 val acc: 51.70 val loss: 0.0031
2023-04-16 16:42:29,795 [INFO] Saving best model with val_acc: 51.696
2023-04-16 16:42:36,162 [INFO] Sub epoch 2 train acc: 46.66 train loss: 0.0063 val acc: 52.46 val loss: 0.0030
2023-04-16 16:42:36,162 [INFO] Saving best model with val_acc: 52.464
2023-04-16 16:42:42,845 [INFO] Sub epoch 3 train acc: 47.20 train loss: 0.0062 val acc: 52.91 val loss: 0.0030
2023-04-16 16:42:42,846 [INFO] Saving best model with val_acc: 52.912
2023-04-16 16:42:49,297 [INFO] Sub epoch 4 train acc: 47.23 train loss: 0.0062 val acc: 52.83 val loss: 0.0030
2023-04-16 16:42:55,439 [INFO] Sub epoch 5 train acc: 47.70 train loss: 0.0062 val acc: 53.38 val loss: 0.0029
2023-04-16 16:42:55,440 [INFO] Saving best model with val_acc: 53.376
2023-04-16 16:43:02,064 [INFO] Sub epoch 6 train acc: 47.58 train loss: 0.0062 val acc: 52.99 val loss: 0.0029
2023-04-16 16:43:08,542 [INFO] Sub epoch 7 train acc: 47.74 train loss: 0.0061 val acc: 53.26 val loss: 0.0029
2023-04-16 16:43:14,509 [INFO] Sub epoch 8 train acc: 47.58 train loss: 0.0061 val acc: 53.01 val loss: 0.0030
2023-04-16 16:43:20,892 [INFO] Sub epoch 9 train acc: 47.67 train loss: 0.0061 val acc: 53.60 val loss: 0.0029
2023-04-16 16:43:20,892 [INFO] Saving best model with val_acc: 53.6
2023-04-16 16:43:27,420 [INFO] Sub epoch 10 train acc: 46.75 train loss: 0.0062 val acc: 53.90 val loss: 0.0029
2023-04-16 16:43:27,420 [INFO] Saving best model with val_acc: 53.904
2023-04-16 16:43:33,544 [INFO] Sub epoch 11 train acc: 47.69 train loss: 0.0061 val acc: 54.02 val loss: 0.0029
2023-04-16 16:43:33,545 [INFO] Saving best model with val_acc: 54.016
2023-04-16 16:43:40,114 [INFO] Sub epoch 12 train acc: 47.73 train loss: 0.0061 val acc: 53.10 val loss: 0.0030
2023-04-16 16:43:46,478 [INFO] Sub epoch 13 train acc: 47.69 train loss: 0.0061 val acc: 53.57 val loss: 0.0029
2023-04-16 16:43:52,671 [INFO] Sub epoch 14 train acc: 47.41 train loss: 0.0061 val acc: 53.98 val loss: 0.0029
2023-04-16 16:43:58,872 [INFO] Sub epoch 15 train acc: 47.44 train loss: 0.0062 val acc: 54.26 val loss: 0.0029
2023-04-16 16:43:58,872 [INFO] Saving best model with val_acc: 54.256
2023-04-16 16:44:05,431 [INFO] Sub epoch 16 train acc: 47.46 train loss: 0.0061 val acc: 53.73 val loss: 0.0029
2023-04-16 16:44:11,632 [INFO] Sub epoch 17 train acc: 47.65 train loss: 0.0062 val acc: 54.69 val loss: 0.0029
2023-04-16 16:44:11,632 [INFO] Saving best model with val_acc: 54.688
2023-04-16 16:44:17,919 [INFO] Sub epoch 18 train acc: 47.82 train loss: 0.0061 val acc: 53.65 val loss: 0.0029
2023-04-16 16:44:24,012 [INFO] Sub epoch 19 train acc: 47.35 train loss: 0.0062 val acc: 54.64 val loss: 0.0029
2023-04-16 16:44:25,325 [INFO] Train Loss: 0.0062, Train Acc: 47.35,  Validation Loss: 0.0029, Validation Acc: 54.64
2023-04-16 16:44:25,343 [INFO] Used supporting modules base weights
2023-04-16 16:44:25,343 [INFO] Training on 43750 samples
2023-04-16 16:44:31,520 [INFO] Sub epoch 0 train acc: 38.53 train loss: 0.0072 val acc: 50.61 val loss: 0.0061
2023-04-16 16:44:31,520 [INFO] Saving best model with val_acc: 50.608
2023-04-16 16:44:37,970 [INFO] Sub epoch 1 train acc: 45.43 train loss: 0.0064 val acc: 52.42 val loss: 0.0033
2023-04-16 16:44:37,970 [INFO] Saving best model with val_acc: 52.416
2023-04-16 16:44:44,067 [INFO] Sub epoch 2 train acc: 46.79 train loss: 0.0063 val acc: 53.23 val loss: 0.0195
2023-04-16 16:44:44,068 [INFO] Saving best model with val_acc: 53.232
2023-04-16 16:44:50,571 [INFO] Sub epoch 3 train acc: 47.08 train loss: 0.0062 val acc: 53.23 val loss: 0.0029
2023-04-16 16:44:56,794 [INFO] Sub epoch 4 train acc: 46.95 train loss: 0.0062 val acc: 53.89 val loss: 0.0029
2023-04-16 16:44:56,794 [INFO] Saving best model with val_acc: 53.888
2023-04-16 16:45:03,186 [INFO] Sub epoch 5 train acc: 46.92 train loss: 0.0062 val acc: 53.95 val loss: 0.0055
2023-04-16 16:45:03,187 [INFO] Saving best model with val_acc: 53.952
2023-04-16 16:45:09,984 [INFO] Sub epoch 6 train acc: 47.10 train loss: 0.0062 val acc: 54.66 val loss: 0.0589
2023-04-16 16:45:09,985 [INFO] Saving best model with val_acc: 54.656
2023-04-16 16:45:16,524 [INFO] Sub epoch 7 train acc: 47.69 train loss: 0.0061 val acc: 54.42 val loss: 0.0543
2023-04-16 16:45:22,736 [INFO] Sub epoch 8 train acc: 47.68 train loss: 0.0061 val acc: 53.73 val loss: 0.0029
2023-04-16 16:45:28,939 [INFO] Sub epoch 9 train acc: 47.67 train loss: 0.0061 val acc: 54.51 val loss: 0.0039
2023-04-16 16:45:35,181 [INFO] Sub epoch 10 train acc: 47.47 train loss: 0.0062 val acc: 54.37 val loss: 0.0028
2023-04-16 16:45:41,179 [INFO] Sub epoch 11 train acc: 47.54 train loss: 0.0061 val acc: 54.03 val loss: 0.0028
2023-04-16 16:45:47,675 [INFO] Sub epoch 12 train acc: 47.41 train loss: 0.0062 val acc: 54.38 val loss: 0.0212
2023-04-16 16:45:53,835 [INFO] Sub epoch 13 train acc: 47.60 train loss: 0.0061 val acc: 54.27 val loss: 0.0028
2023-04-16 16:45:59,974 [INFO] Sub epoch 14 train acc: 47.53 train loss: 0.0061 val acc: 54.14 val loss: 0.0028
2023-04-16 16:46:06,385 [INFO] Sub epoch 15 train acc: 47.78 train loss: 0.0061 val acc: 54.43 val loss: 0.0375
2023-04-16 16:46:12,444 [INFO] Sub epoch 16 train acc: 47.32 train loss: 0.0061 val acc: 54.83 val loss: 0.0868
2023-04-16 16:46:12,444 [INFO] Saving best model with val_acc: 54.832
2023-04-16 16:46:19,171 [INFO] Sub epoch 17 train acc: 47.38 train loss: 0.0062 val acc: 53.94 val loss: 0.0029
2023-04-16 16:46:25,571 [INFO] Sub epoch 18 train acc: 47.91 train loss: 0.0061 val acc: 54.51 val loss: 0.0028
2023-04-16 16:46:31,829 [INFO] Sub epoch 19 train acc: 47.38 train loss: 0.0061 val acc: 54.61 val loss: 0.0474
2023-04-16 16:46:33,159 [INFO] Train Loss: 0.0061, Train Acc: 47.38,  Validation Loss: 0.0474, Validation Acc: 54.61
2023-04-16 16:46:33,179 [INFO] Used supporting modules base weights
2023-04-16 16:46:33,179 [INFO] Training on 43750 samples
2023-04-16 16:46:39,616 [INFO] Sub epoch 0 train acc: 38.15 train loss: 0.0072 val acc: 49.39 val loss: 0.0032
2023-04-16 16:46:39,617 [INFO] Saving best model with val_acc: 49.392
2023-04-16 16:46:46,228 [INFO] Sub epoch 1 train acc: 46.04 train loss: 0.0064 val acc: 51.09 val loss: 0.0096
2023-04-16 16:46:46,228 [INFO] Saving best model with val_acc: 51.088
2023-04-16 16:46:52,689 [INFO] Sub epoch 2 train acc: 46.38 train loss: 0.0063 val acc: 52.32 val loss: 0.0142
2023-04-16 16:46:52,690 [INFO] Saving best model with val_acc: 52.32
2023-04-16 16:46:59,844 [INFO] Sub epoch 3 train acc: 47.26 train loss: 0.0062 val acc: 52.70 val loss: 0.0078
2023-04-16 16:46:59,845 [INFO] Saving best model with val_acc: 52.704
2023-04-16 16:47:06,273 [INFO] Sub epoch 4 train acc: 47.08 train loss: 0.0062 val acc: 52.66 val loss: 0.0074
2023-04-16 16:47:12,485 [INFO] Sub epoch 5 train acc: 47.60 train loss: 0.0062 val acc: 52.54 val loss: 0.0049
2023-04-16 16:47:18,950 [INFO] Sub epoch 6 train acc: 47.49 train loss: 0.0062 val acc: 52.61 val loss: 0.0030
2023-04-16 16:47:25,097 [INFO] Sub epoch 7 train acc: 47.66 train loss: 0.0062 val acc: 52.80 val loss: 0.0035
2023-04-16 16:47:25,098 [INFO] Saving best model with val_acc: 52.8
2023-04-16 16:47:31,935 [INFO] Sub epoch 8 train acc: 47.55 train loss: 0.0062 val acc: 53.17 val loss: 0.0032
2023-04-16 16:47:31,936 [INFO] Saving best model with val_acc: 53.168
2023-04-16 16:47:38,573 [INFO] Sub epoch 9 train acc: 47.58 train loss: 0.0061 val acc: 52.86 val loss: 0.0292
2023-04-16 16:47:45,104 [INFO] Sub epoch 10 train acc: 47.26 train loss: 0.0062 val acc: 53.06 val loss: 0.0108
2023-04-16 16:47:51,730 [INFO] Sub epoch 11 train acc: 47.28 train loss: 0.0062 val acc: 53.49 val loss: 0.0031
2023-04-16 16:47:51,731 [INFO] Saving best model with val_acc: 53.488
2023-04-16 16:47:58,341 [INFO] Sub epoch 12 train acc: 47.10 train loss: 0.0062 val acc: 53.65 val loss: 0.0497
2023-04-16 16:47:58,341 [INFO] Saving best model with val_acc: 53.648
2023-04-16 16:48:05,204 [INFO] Sub epoch 13 train acc: 47.63 train loss: 0.0061 val acc: 52.78 val loss: 0.0183
2023-04-16 16:48:11,573 [INFO] Sub epoch 14 train acc: 47.40 train loss: 0.0062 val acc: 52.56 val loss: 0.0056
2023-04-16 16:48:18,271 [INFO] Sub epoch 15 train acc: 47.24 train loss: 0.0062 val acc: 52.98 val loss: 0.0030
2023-04-16 16:48:24,465 [INFO] Sub epoch 16 train acc: 47.33 train loss: 0.0062 val acc: 53.33 val loss: 0.0113
2023-04-16 16:48:30,822 [INFO] Sub epoch 17 train acc: 47.64 train loss: 0.0062 val acc: 53.81 val loss: 0.0034
2023-04-16 16:48:30,822 [INFO] Saving best model with val_acc: 53.808
2023-04-16 16:48:37,313 [INFO] Sub epoch 18 train acc: 47.49 train loss: 0.0062 val acc: 52.94 val loss: 0.0306
2023-04-16 16:48:43,446 [INFO] Sub epoch 19 train acc: 47.27 train loss: 0.0062 val acc: 53.52 val loss: 0.0034
2023-04-16 16:48:44,768 [INFO] Train Loss: 0.0062, Train Acc: 47.27,  Validation Loss: 0.0034, Validation Acc: 53.52
2023-04-16 16:48:44,786 [INFO] Used supporting modules base weights
2023-04-16 16:48:44,786 [INFO] Training on 43750 samples
2023-04-16 16:48:51,232 [INFO] Sub epoch 0 train acc: 38.56 train loss: 0.0071 val acc: 51.14 val loss: 0.0031
2023-04-16 16:48:51,232 [INFO] Saving best model with val_acc: 51.136
2023-04-16 16:48:57,999 [INFO] Sub epoch 1 train acc: 45.59 train loss: 0.0064 val acc: 52.51 val loss: 0.0030
2023-04-16 16:48:57,999 [INFO] Saving best model with val_acc: 52.512
2023-04-16 16:49:04,371 [INFO] Sub epoch 2 train acc: 46.48 train loss: 0.0063 val acc: 52.86 val loss: 0.0031
2023-04-16 16:49:04,371 [INFO] Saving best model with val_acc: 52.864
2023-04-16 16:49:11,121 [INFO] Sub epoch 3 train acc: 47.18 train loss: 0.0062 val acc: 53.52 val loss: 0.0030
2023-04-16 16:49:11,122 [INFO] Saving best model with val_acc: 53.52
2023-04-16 16:49:17,958 [INFO] Sub epoch 4 train acc: 47.07 train loss: 0.0062 val acc: 53.84 val loss: 0.0029
2023-04-16 16:49:17,959 [INFO] Saving best model with val_acc: 53.84
2023-04-16 16:49:24,450 [INFO] Sub epoch 5 train acc: 47.35 train loss: 0.0062 val acc: 54.22 val loss: 0.0029
2023-04-16 16:49:24,450 [INFO] Saving best model with val_acc: 54.224
2023-04-16 16:49:30,870 [INFO] Sub epoch 6 train acc: 47.27 train loss: 0.0062 val acc: 54.62 val loss: 0.0028
2023-04-16 16:49:30,870 [INFO] Saving best model with val_acc: 54.624
2023-04-16 16:49:37,309 [INFO] Sub epoch 7 train acc: 47.31 train loss: 0.0062 val acc: 53.73 val loss: 0.0029
2023-04-16 16:49:43,709 [INFO] Sub epoch 8 train acc: 47.37 train loss: 0.0062 val acc: 53.39 val loss: 0.0028
2023-04-16 16:49:49,968 [INFO] Sub epoch 9 train acc: 47.37 train loss: 0.0062 val acc: 54.22 val loss: 0.0029
2023-04-16 16:49:56,355 [INFO] Sub epoch 10 train acc: 47.24 train loss: 0.0062 val acc: 53.90 val loss: 0.0028
2023-04-16 16:50:02,640 [INFO] Sub epoch 11 train acc: 47.37 train loss: 0.0062 val acc: 54.91 val loss: 0.0028
2023-04-16 16:50:02,640 [INFO] Saving best model with val_acc: 54.912
2023-04-16 16:50:09,299 [INFO] Sub epoch 12 train acc: 47.57 train loss: 0.0062 val acc: 54.64 val loss: 0.0028
2023-04-16 16:50:15,321 [INFO] Sub epoch 13 train acc: 47.30 train loss: 0.0062 val acc: 53.54 val loss: 0.0029
2023-04-16 16:50:21,645 [INFO] Sub epoch 14 train acc: 47.49 train loss: 0.0061 val acc: 54.64 val loss: 0.0029
2023-04-16 16:50:28,215 [INFO] Sub epoch 15 train acc: 47.43 train loss: 0.0061 val acc: 54.51 val loss: 0.0028
2023-04-16 16:50:34,658 [INFO] Sub epoch 16 train acc: 47.24 train loss: 0.0061 val acc: 54.66 val loss: 0.0028
2023-04-16 16:50:41,130 [INFO] Sub epoch 17 train acc: 47.15 train loss: 0.0062 val acc: 54.40 val loss: 0.0030
2023-04-16 16:50:47,364 [INFO] Sub epoch 18 train acc: 47.37 train loss: 0.0062 val acc: 55.17 val loss: 0.0028
2023-04-16 16:50:47,364 [INFO] Saving best model with val_acc: 55.168
2023-04-16 16:50:53,778 [INFO] Sub epoch 19 train acc: 47.67 train loss: 0.0061 val acc: 54.51 val loss: 0.0028
2023-04-16 16:50:55,113 [INFO] Train Loss: 0.0061, Train Acc: 47.67,  Validation Loss: 0.0028, Validation Acc: 54.51
2023-04-16 16:53:34,963 [INFO] Training started
2023-04-16 16:53:34,977 [INFO] Using cuda
2023-04-16 16:53:36,817 [INFO] Loaded CIFAR10
2023-04-16 16:53:36,845 [INFO] Training indices read from params/train_idx.csv
2023-04-16 16:53:36,849 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 16:53:38,014 [INFO] Loaded VGG16 with default pretrained weights
2023-04-16 16:53:38,015 [INFO] Classifier modified to 10 classes
2023-04-16 16:53:44,966 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 16:53:44,966 [INFO] Loaded Cross Entropy Loss
2023-04-16 16:53:44,967 [INFO] Loaded LR scheduler
2023-04-16 16:53:45,331 [INFO] Read supporting modules base weights
2023-04-16 16:55:29,621 [INFO] Training started
2023-04-16 16:55:29,633 [INFO] Using cuda
2023-04-16 16:55:31,198 [INFO] Loaded CIFAR10
2023-04-16 16:55:31,221 [INFO] Training indices read from params/train_idx.csv
2023-04-16 16:55:31,225 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 16:55:32,028 [INFO] Loaded VGG16 with default pretrained weights
2023-04-16 16:55:32,029 [INFO] Classifier modified to 10 classes
2023-04-16 16:55:36,275 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 16:55:36,275 [INFO] Loaded Cross Entropy Loss
2023-04-16 16:55:36,276 [INFO] Loaded LR scheduler
2023-04-16 16:55:36,846 [INFO] Generated supporting modules base weights
2023-04-16 16:55:37,227 [INFO] Read supporting modules base weights
2023-04-16 16:55:37,236 [INFO] Used supporting modules base weights
2023-04-16 16:55:37,236 [INFO] Training on 43750 samples
2023-04-16 16:56:11,208 [INFO] Sub epoch 0 train acc: 66.86 train loss: 0.0039 val acc: 73.66 val loss: 0.0016
2023-04-16 16:56:11,209 [INFO] Saving best model with val_acc: 73.664
2023-04-16 16:56:24,300 [INFO] Sub epoch 1 train acc: 73.74 train loss: 0.0030 val acc: 74.56 val loss: 0.0015
2023-04-16 16:56:24,300 [INFO] Saving best model with val_acc: 74.56
2023-04-16 16:56:37,454 [INFO] Sub epoch 2 train acc: 75.84 train loss: 0.0028 val acc: 76.96 val loss: 0.0014
2023-04-16 16:56:37,454 [INFO] Saving best model with val_acc: 76.96
2023-04-16 16:56:50,647 [INFO] Sub epoch 3 train acc: 77.26 train loss: 0.0027 val acc: 76.88 val loss: 0.0014
2023-04-16 16:57:03,061 [INFO] Sub epoch 4 train acc: 78.89 train loss: 0.0025 val acc: 77.25 val loss: 0.0014
2023-04-16 16:57:03,062 [INFO] Saving best model with val_acc: 77.248
2023-04-16 16:57:16,126 [INFO] Sub epoch 5 train acc: 79.82 train loss: 0.0024 val acc: 77.90 val loss: 0.0014
2023-04-16 16:57:16,126 [INFO] Saving best model with val_acc: 77.904
2023-04-16 16:57:29,289 [INFO] Sub epoch 6 train acc: 81.23 train loss: 0.0022 val acc: 77.55 val loss: 0.0014
2023-04-16 16:57:41,661 [INFO] Sub epoch 7 train acc: 82.41 train loss: 0.0021 val acc: 77.33 val loss: 0.0015
2023-04-16 16:57:54,114 [INFO] Sub epoch 8 train acc: 83.47 train loss: 0.0020 val acc: 77.07 val loss: 0.0015
2023-04-16 16:58:06,456 [INFO] Sub epoch 9 train acc: 84.11 train loss: 0.0019 val acc: 78.45 val loss: 0.0015
2023-04-16 16:58:06,456 [INFO] Saving best model with val_acc: 78.448
2023-04-16 16:58:19,480 [INFO] Sub epoch 10 train acc: 84.94 train loss: 0.0018 val acc: 78.32 val loss: 0.0015
2023-04-16 16:58:31,861 [INFO] Sub epoch 11 train acc: 85.84 train loss: 0.0017 val acc: 78.05 val loss: 0.0015
2023-04-16 16:58:44,172 [INFO] Sub epoch 12 train acc: 86.61 train loss: 0.0016 val acc: 77.84 val loss: 0.0015
2023-04-16 16:58:56,472 [INFO] Sub epoch 13 train acc: 87.27 train loss: 0.0015 val acc: 78.43 val loss: 0.0015
2023-04-16 16:59:08,820 [INFO] Sub epoch 14 train acc: 87.70 train loss: 0.0015 val acc: 78.29 val loss: 0.0016
2023-04-16 16:59:21,117 [INFO] Sub epoch 15 train acc: 88.62 train loss: 0.0014 val acc: 78.50 val loss: 0.0016
2023-04-16 16:59:21,118 [INFO] Saving best model with val_acc: 78.496
2023-04-16 16:59:34,238 [INFO] Sub epoch 16 train acc: 88.83 train loss: 0.0014 val acc: 78.10 val loss: 0.0018
2023-04-16 16:59:46,597 [INFO] Sub epoch 17 train acc: 89.55 train loss: 0.0013 val acc: 78.43 val loss: 0.0017
2023-04-16 16:59:58,931 [INFO] Sub epoch 18 train acc: 91.89 train loss: 0.0010 val acc: 79.38 val loss: 0.0017
2023-04-16 16:59:58,931 [INFO] Saving best model with val_acc: 79.376
2023-04-16 17:00:11,961 [INFO] Sub epoch 19 train acc: 93.45 train loss: 0.0008 val acc: 79.25 val loss: 0.0018
2023-04-16 17:00:15,280 [INFO] Train Loss: 0.0008, Train Acc: 93.45,  Validation Loss: 0.0018, Validation Acc: 79.25
2023-04-16 17:00:15,283 [INFO] Used supporting modules base weights
2023-04-16 17:00:15,284 [INFO] Training on 43750 samples
2023-04-16 17:00:27,680 [INFO] Sub epoch 0 train acc: 66.73 train loss: 0.0039 val acc: 73.66 val loss: 0.0016
2023-04-16 17:00:27,680 [INFO] Saving best model with val_acc: 73.664
2023-04-16 17:00:40,614 [INFO] Sub epoch 1 train acc: 73.60 train loss: 0.0031 val acc: 76.62 val loss: 0.0015
2023-04-16 17:00:40,615 [INFO] Saving best model with val_acc: 76.624
2023-04-16 17:00:53,822 [INFO] Sub epoch 2 train acc: 76.11 train loss: 0.0028 val acc: 75.86 val loss: 0.0015
2023-04-16 17:01:06,111 [INFO] Sub epoch 3 train acc: 77.44 train loss: 0.0026 val acc: 76.78 val loss: 0.0014
2023-04-16 17:01:06,112 [INFO] Saving best model with val_acc: 76.784
2023-04-16 17:01:19,299 [INFO] Sub epoch 4 train acc: 78.63 train loss: 0.0025 val acc: 76.61 val loss: 0.0015
2023-04-16 17:01:31,566 [INFO] Sub epoch 5 train acc: 80.14 train loss: 0.0024 val acc: 78.58 val loss: 0.0014
2023-04-16 17:01:31,566 [INFO] Saving best model with val_acc: 78.576
2023-04-16 17:01:44,711 [INFO] Sub epoch 6 train acc: 80.88 train loss: 0.0023 val acc: 77.94 val loss: 0.0014
2023-04-16 17:01:57,133 [INFO] Sub epoch 7 train acc: 82.15 train loss: 0.0021 val acc: 78.43 val loss: 0.0014
2023-04-16 17:02:09,540 [INFO] Sub epoch 8 train acc: 83.32 train loss: 0.0020 val acc: 78.53 val loss: 0.0014
2023-04-16 17:02:21,953 [INFO] Sub epoch 9 train acc: 84.27 train loss: 0.0019 val acc: 77.46 val loss: 0.0015
2023-04-16 17:02:34,259 [INFO] Sub epoch 10 train acc: 85.04 train loss: 0.0018 val acc: 78.61 val loss: 0.0015
2023-04-16 17:02:34,260 [INFO] Saving best model with val_acc: 78.608
2023-04-16 17:02:47,361 [INFO] Sub epoch 11 train acc: 85.89 train loss: 0.0017 val acc: 78.85 val loss: 0.0015
2023-04-16 17:02:47,361 [INFO] Saving best model with val_acc: 78.848
2023-04-16 17:03:00,396 [INFO] Sub epoch 12 train acc: 86.34 train loss: 0.0016 val acc: 78.40 val loss: 0.0015
2023-04-16 17:03:12,671 [INFO] Sub epoch 13 train acc: 87.45 train loss: 0.0015 val acc: 78.54 val loss: 0.0015
2023-04-16 17:03:25,015 [INFO] Sub epoch 14 train acc: 88.47 train loss: 0.0014 val acc: 78.75 val loss: 0.0016
2023-04-16 17:03:37,511 [INFO] Sub epoch 15 train acc: 88.68 train loss: 0.0014 val acc: 79.68 val loss: 0.0016
2023-04-16 17:03:37,512 [INFO] Saving best model with val_acc: 79.68
2023-04-16 17:03:50,781 [INFO] Sub epoch 16 train acc: 88.81 train loss: 0.0014 val acc: 78.38 val loss: 0.0017
2023-04-16 17:04:03,320 [INFO] Sub epoch 17 train acc: 91.67 train loss: 0.0010 val acc: 78.91 val loss: 0.0016
2023-04-16 17:04:15,815 [INFO] Sub epoch 18 train acc: 93.10 train loss: 0.0008 val acc: 79.34 val loss: 0.0017
2023-04-16 17:04:28,185 [INFO] Sub epoch 19 train acc: 94.00 train loss: 0.0007 val acc: 78.88 val loss: 0.0017
2023-04-16 17:04:29,958 [INFO] Train Loss: 0.0007, Train Acc: 94.00,  Validation Loss: 0.0017, Validation Acc: 78.88
2023-04-16 17:04:29,961 [INFO] Used supporting modules base weights
2023-04-16 17:04:29,961 [INFO] Training on 43750 samples
2023-04-16 17:04:42,372 [INFO] Sub epoch 0 train acc: 66.63 train loss: 0.0039 val acc: 74.72 val loss: 0.0016
2023-04-16 17:04:42,372 [INFO] Saving best model with val_acc: 74.72
2023-04-16 17:04:55,665 [INFO] Sub epoch 1 train acc: 73.84 train loss: 0.0030 val acc: 76.75 val loss: 0.0014
2023-04-16 17:04:55,665 [INFO] Saving best model with val_acc: 76.752
2023-04-16 17:05:08,902 [INFO] Sub epoch 2 train acc: 75.68 train loss: 0.0029 val acc: 76.38 val loss: 0.0015
2023-04-16 17:05:21,317 [INFO] Sub epoch 3 train acc: 77.47 train loss: 0.0026 val acc: 77.33 val loss: 0.0014
2023-04-16 17:05:21,317 [INFO] Saving best model with val_acc: 77.328
2023-04-16 17:05:34,380 [INFO] Sub epoch 4 train acc: 78.58 train loss: 0.0025 val acc: 77.33 val loss: 0.0014
2023-04-16 17:05:46,871 [INFO] Sub epoch 5 train acc: 79.77 train loss: 0.0024 val acc: 77.86 val loss: 0.0014
2023-04-16 17:05:46,872 [INFO] Saving best model with val_acc: 77.856
2023-04-16 17:06:00,027 [INFO] Sub epoch 6 train acc: 81.30 train loss: 0.0022 val acc: 78.08 val loss: 0.0014
2023-04-16 17:06:00,028 [INFO] Saving best model with val_acc: 78.08
2023-04-16 17:06:13,289 [INFO] Sub epoch 7 train acc: 82.13 train loss: 0.0021 val acc: 77.73 val loss: 0.0014
2023-04-16 17:06:25,662 [INFO] Sub epoch 8 train acc: 83.41 train loss: 0.0020 val acc: 77.76 val loss: 0.0014
2023-04-16 17:06:37,987 [INFO] Sub epoch 9 train acc: 84.26 train loss: 0.0019 val acc: 78.11 val loss: 0.0014
2023-04-16 17:06:37,987 [INFO] Saving best model with val_acc: 78.112
2023-04-16 17:06:51,096 [INFO] Sub epoch 10 train acc: 85.15 train loss: 0.0018 val acc: 78.64 val loss: 0.0014
2023-04-16 17:06:51,097 [INFO] Saving best model with val_acc: 78.64
2023-04-16 17:07:04,149 [INFO] Sub epoch 11 train acc: 86.23 train loss: 0.0016 val acc: 78.27 val loss: 0.0015
2023-04-16 17:07:16,544 [INFO] Sub epoch 12 train acc: 86.82 train loss: 0.0016 val acc: 78.82 val loss: 0.0015
2023-04-16 17:07:16,545 [INFO] Saving best model with val_acc: 78.816
2023-04-16 17:07:29,588 [INFO] Sub epoch 13 train acc: 87.06 train loss: 0.0016 val acc: 78.18 val loss: 0.0016
2023-04-16 17:07:42,086 [INFO] Sub epoch 14 train acc: 87.69 train loss: 0.0015 val acc: 78.13 val loss: 0.0016
2023-04-16 17:07:54,438 [INFO] Sub epoch 15 train acc: 88.37 train loss: 0.0014 val acc: 78.54 val loss: 0.0016
2023-04-16 17:08:06,940 [INFO] Sub epoch 16 train acc: 89.05 train loss: 0.0014 val acc: 78.88 val loss: 0.0017
2023-04-16 17:08:06,941 [INFO] Saving best model with val_acc: 78.88
2023-04-16 17:08:20,039 [INFO] Sub epoch 17 train acc: 91.69 train loss: 0.0010 val acc: 79.76 val loss: 0.0016
2023-04-16 17:08:20,039 [INFO] Saving best model with val_acc: 79.76
2023-04-16 17:08:33,092 [INFO] Sub epoch 18 train acc: 93.09 train loss: 0.0008 val acc: 80.00 val loss: 0.0017
2023-04-16 17:08:33,093 [INFO] Saving best model with val_acc: 80.0
2023-04-16 17:08:46,131 [INFO] Sub epoch 19 train acc: 94.00 train loss: 0.0007 val acc: 80.08 val loss: 0.0017
2023-04-16 17:08:46,131 [INFO] Saving best model with val_acc: 80.08
2023-04-16 17:08:48,657 [INFO] Train Loss: 0.0007, Train Acc: 94.00,  Validation Loss: 0.0017, Validation Acc: 80.08
2023-04-16 17:08:48,660 [INFO] Used supporting modules base weights
2023-04-16 17:08:48,660 [INFO] Training on 43750 samples
2023-04-16 17:09:01,048 [INFO] Sub epoch 0 train acc: 67.17 train loss: 0.0038 val acc: 75.92 val loss: 0.0014
2023-04-16 17:09:01,048 [INFO] Saving best model with val_acc: 75.92
2023-04-16 17:09:14,238 [INFO] Sub epoch 1 train acc: 73.65 train loss: 0.0031 val acc: 76.02 val loss: 0.0015
2023-04-16 17:09:14,239 [INFO] Saving best model with val_acc: 76.016
2023-04-16 17:09:27,359 [INFO] Sub epoch 2 train acc: 75.78 train loss: 0.0028 val acc: 77.33 val loss: 0.0014
2023-04-16 17:09:27,359 [INFO] Saving best model with val_acc: 77.328
2023-04-16 17:09:40,579 [INFO] Sub epoch 3 train acc: 77.23 train loss: 0.0027 val acc: 77.68 val loss: 0.0014
2023-04-16 17:09:40,579 [INFO] Saving best model with val_acc: 77.68
2023-04-16 17:09:53,672 [INFO] Sub epoch 4 train acc: 78.55 train loss: 0.0025 val acc: 77.25 val loss: 0.0014
2023-04-16 17:10:06,081 [INFO] Sub epoch 5 train acc: 79.68 train loss: 0.0024 val acc: 78.29 val loss: 0.0013
2023-04-16 17:10:06,082 [INFO] Saving best model with val_acc: 78.288
2023-04-16 17:10:19,075 [INFO] Sub epoch 6 train acc: 81.16 train loss: 0.0022 val acc: 78.22 val loss: 0.0014
2023-04-16 17:10:31,331 [INFO] Sub epoch 7 train acc: 82.54 train loss: 0.0021 val acc: 78.32 val loss: 0.0014
2023-04-16 17:10:31,331 [INFO] Saving best model with val_acc: 78.32
2023-04-16 17:10:44,332 [INFO] Sub epoch 8 train acc: 83.12 train loss: 0.0020 val acc: 78.38 val loss: 0.0014
2023-04-16 17:10:44,333 [INFO] Saving best model with val_acc: 78.384
2023-04-16 17:10:57,293 [INFO] Sub epoch 9 train acc: 84.14 train loss: 0.0019 val acc: 77.95 val loss: 0.0015
2023-04-16 17:11:09,669 [INFO] Sub epoch 10 train acc: 85.39 train loss: 0.0017 val acc: 78.82 val loss: 0.0014
2023-04-16 17:11:09,669 [INFO] Saving best model with val_acc: 78.816
2023-04-16 17:11:22,852 [INFO] Sub epoch 11 train acc: 86.06 train loss: 0.0017 val acc: 78.29 val loss: 0.0014
2023-04-16 17:11:35,194 [INFO] Sub epoch 12 train acc: 86.67 train loss: 0.0016 val acc: 78.98 val loss: 0.0015
2023-04-16 17:11:35,194 [INFO] Saving best model with val_acc: 78.976
2023-04-16 17:11:48,283 [INFO] Sub epoch 13 train acc: 86.89 train loss: 0.0016 val acc: 79.70 val loss: 0.0015
2023-04-16 17:11:48,283 [INFO] Saving best model with val_acc: 79.696
2023-04-16 17:12:01,479 [INFO] Sub epoch 14 train acc: 87.71 train loss: 0.0015 val acc: 79.73 val loss: 0.0015
2023-04-16 17:12:01,479 [INFO] Saving best model with val_acc: 79.728
2023-04-16 17:12:14,629 [INFO] Sub epoch 15 train acc: 88.50 train loss: 0.0014 val acc: 78.82 val loss: 0.0015
2023-04-16 17:12:26,973 [INFO] Sub epoch 16 train acc: 89.00 train loss: 0.0014 val acc: 79.57 val loss: 0.0015
2023-04-16 17:12:39,279 [INFO] Sub epoch 17 train acc: 91.69 train loss: 0.0010 val acc: 79.95 val loss: 0.0015
2023-04-16 17:12:39,280 [INFO] Saving best model with val_acc: 79.952
2023-04-16 17:12:52,254 [INFO] Sub epoch 18 train acc: 93.16 train loss: 0.0008 val acc: 80.29 val loss: 0.0016
2023-04-16 17:12:52,255 [INFO] Saving best model with val_acc: 80.288
2023-04-16 17:13:05,276 [INFO] Sub epoch 19 train acc: 94.05 train loss: 0.0007 val acc: 80.32 val loss: 0.0016
2023-04-16 17:13:05,276 [INFO] Saving best model with val_acc: 80.32
2023-04-16 17:13:07,720 [INFO] Train Loss: 0.0007, Train Acc: 94.05,  Validation Loss: 0.0016, Validation Acc: 80.32
2023-04-16 17:13:07,724 [INFO] Used supporting modules base weights
2023-04-16 17:13:07,724 [INFO] Training on 43750 samples
2023-04-16 17:13:20,061 [INFO] Sub epoch 0 train acc: 66.97 train loss: 0.0038 val acc: 75.20 val loss: 0.0015
2023-04-16 17:13:20,061 [INFO] Saving best model with val_acc: 75.2
2023-04-16 17:13:33,032 [INFO] Sub epoch 1 train acc: 73.78 train loss: 0.0030 val acc: 75.52 val loss: 0.0015
2023-04-16 17:13:33,033 [INFO] Saving best model with val_acc: 75.52
2023-04-16 17:13:45,997 [INFO] Sub epoch 2 train acc: 75.65 train loss: 0.0028 val acc: 77.23 val loss: 0.0014
2023-04-16 17:13:45,997 [INFO] Saving best model with val_acc: 77.232
2023-04-16 17:13:58,958 [INFO] Sub epoch 3 train acc: 77.07 train loss: 0.0027 val acc: 76.67 val loss: 0.0015
2023-04-16 17:14:11,290 [INFO] Sub epoch 4 train acc: 78.31 train loss: 0.0026 val acc: 77.66 val loss: 0.0014
2023-04-16 17:14:11,290 [INFO] Saving best model with val_acc: 77.664
2023-04-16 17:14:24,233 [INFO] Sub epoch 5 train acc: 79.90 train loss: 0.0024 val acc: 78.30 val loss: 0.0014
2023-04-16 17:14:24,233 [INFO] Saving best model with val_acc: 78.304
2023-04-16 17:14:37,283 [INFO] Sub epoch 6 train acc: 80.77 train loss: 0.0023 val acc: 77.63 val loss: 0.0015
2023-04-16 17:14:49,614 [INFO] Sub epoch 7 train acc: 81.88 train loss: 0.0021 val acc: 78.54 val loss: 0.0014
2023-04-16 17:14:49,614 [INFO] Saving best model with val_acc: 78.544
2023-04-16 17:15:02,581 [INFO] Sub epoch 8 train acc: 82.99 train loss: 0.0020 val acc: 78.35 val loss: 0.0015
2023-04-16 17:15:14,904 [INFO] Sub epoch 9 train acc: 83.74 train loss: 0.0019 val acc: 78.53 val loss: 0.0014
2023-04-16 17:15:27,213 [INFO] Sub epoch 10 train acc: 84.92 train loss: 0.0018 val acc: 78.83 val loss: 0.0015
2023-04-16 17:15:27,213 [INFO] Saving best model with val_acc: 78.832
2023-04-16 17:15:40,272 [INFO] Sub epoch 11 train acc: 85.28 train loss: 0.0018 val acc: 78.24 val loss: 0.0015
2023-04-16 17:15:52,714 [INFO] Sub epoch 12 train acc: 86.16 train loss: 0.0017 val acc: 78.50 val loss: 0.0015
2023-04-16 17:16:05,119 [INFO] Sub epoch 13 train acc: 87.00 train loss: 0.0016 val acc: 78.82 val loss: 0.0016
2023-04-16 17:16:17,505 [INFO] Sub epoch 14 train acc: 87.39 train loss: 0.0015 val acc: 78.62 val loss: 0.0016
2023-04-16 17:16:29,842 [INFO] Sub epoch 15 train acc: 88.27 train loss: 0.0014 val acc: 78.86 val loss: 0.0016
2023-04-16 17:16:29,843 [INFO] Saving best model with val_acc: 78.864
2023-04-16 17:16:42,864 [INFO] Sub epoch 16 train acc: 89.11 train loss: 0.0013 val acc: 79.12 val loss: 0.0017
2023-04-16 17:16:42,865 [INFO] Saving best model with val_acc: 79.12
2023-04-16 17:16:56,009 [INFO] Sub epoch 17 train acc: 91.21 train loss: 0.0010 val acc: 80.22 val loss: 0.0016
2023-04-16 17:16:56,010 [INFO] Saving best model with val_acc: 80.224
2023-04-16 17:17:09,059 [INFO] Sub epoch 18 train acc: 92.88 train loss: 0.0008 val acc: 80.34 val loss: 0.0017
2023-04-16 17:17:09,059 [INFO] Saving best model with val_acc: 80.336
2023-04-16 17:17:22,298 [INFO] Sub epoch 19 train acc: 93.75 train loss: 0.0007 val acc: 80.34 val loss: 0.0017
2023-04-16 17:17:24,106 [INFO] Train Loss: 0.0007, Train Acc: 93.75,  Validation Loss: 0.0017, Validation Acc: 80.34
2023-04-16 17:28:11,729 [INFO] Training started
2023-04-16 17:28:11,765 [INFO] Using cuda
2023-04-16 17:28:13,602 [INFO] Loaded CIFAR10
2023-04-16 17:28:13,639 [INFO] Training indices read from params/train_idx.csv
2023-04-16 17:28:13,644 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 17:28:48,219 [INFO] Training started
2023-04-16 17:28:48,231 [INFO] Using cuda
2023-04-16 17:28:49,770 [INFO] Loaded CIFAR10
2023-04-16 17:28:49,792 [INFO] Training indices read from params/train_idx.csv
2023-04-16 17:28:49,796 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 17:28:51,033 [INFO] Loaded VGG16 with default pretrained weights
2023-04-16 17:28:51,034 [INFO] Classifier modified to 10 classes
2023-04-16 17:28:58,059 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 17:28:58,059 [INFO] Loaded Cross Entropy Loss
2023-04-16 17:28:58,059 [INFO] Loaded LR scheduler
2023-04-16 17:28:59,042 [INFO] Read supporting modules base weights
2023-04-16 17:28:59,054 [INFO] Used supporting modules base weights
2023-04-16 17:28:59,054 [INFO] Training on 43750 samples
2023-04-16 18:15:57,773 [INFO] Training started
2023-04-16 18:15:57,809 [INFO] Using cuda
2023-04-16 18:15:59,437 [INFO] Loaded CIFAR10
2023-04-16 18:15:59,459 [INFO] Training indices read from params/train_idx.csv
2023-04-16 18:15:59,463 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 18:16:01,662 [INFO] Loaded VGG16 with default pretrained weights
2023-04-16 18:16:01,663 [INFO] Classifier modified to 10 classes
2023-04-16 18:16:09,645 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 18:16:09,645 [INFO] Loaded Cross Entropy Loss
2023-04-16 18:16:09,645 [INFO] Loaded LR scheduler
2023-04-16 18:16:10,717 [INFO] Read supporting modules base weights
2023-04-16 18:16:10,739 [INFO] Used supporting modules base weights
2023-04-16 18:16:10,739 [INFO] Training on 43750 samples
2023-04-16 18:25:04,041 [INFO] Training started
2023-04-16 18:25:04,053 [INFO] Using cuda
2023-04-16 18:25:05,641 [INFO] Loaded CIFAR10
2023-04-16 18:25:05,665 [INFO] Training indices read from params/train_idx.csv
2023-04-16 18:25:05,668 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 18:25:06,537 [INFO] Loaded VGG16 with default pretrained weights
2023-04-16 18:25:06,537 [INFO] Classifier modified to 10 classes
2023-04-16 18:25:11,177 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 18:25:11,177 [INFO] Loaded Cross Entropy Loss
2023-04-16 18:25:11,177 [INFO] Loaded LR scheduler
2023-04-16 18:25:11,569 [INFO] Read supporting modules base weights
2023-04-16 18:25:11,579 [INFO] Used supporting modules base weights
2023-04-16 18:25:11,579 [INFO] Training on 43750 samples
2023-04-16 18:28:34,712 [INFO] Training started
2023-04-16 18:28:34,818 [INFO] Using cuda
2023-04-16 18:28:36,715 [INFO] Loaded CIFAR10
2023-04-16 18:28:36,748 [INFO] Training indices read from params/train_idx.csv
2023-04-16 18:28:36,754 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 18:28:38,010 [INFO] Loaded VGG16 with default pretrained weights
2023-04-16 18:28:38,011 [INFO] Classifier modified to 10 classes
2023-04-16 18:28:45,359 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 18:28:45,360 [INFO] Loaded Cross Entropy Loss
2023-04-16 18:28:45,360 [INFO] Loaded LR scheduler
2023-04-16 18:28:46,384 [INFO] Read supporting modules base weights
2023-04-16 18:28:46,394 [INFO] Used supporting modules base weights
2023-04-16 18:28:46,394 [INFO] Training on 43750 samples
2023-04-16 18:31:07,768 [INFO] Sub epoch 0 train acc: 73.03 train loss: 0.0290 val acc: 79.39 val loss: 0.0095
2023-04-16 18:31:07,769 [INFO] Saving best model with val_acc: 79.392
2023-04-16 18:33:10,384 [INFO] Sub epoch 1 train acc: 80.80 train loss: 0.0216 val acc: 83.12 val loss: 0.0088
2023-04-16 18:33:10,385 [INFO] Saving best model with val_acc: 83.12
2023-04-16 18:35:12,391 [INFO] Sub epoch 2 train acc: 83.78 train loss: 0.0189 val acc: 84.05 val loss: 0.0086
2023-04-16 18:35:12,391 [INFO] Saving best model with val_acc: 84.048
2023-04-16 18:37:53,408 [INFO] Training started
2023-04-16 18:37:53,422 [INFO] Using cuda
2023-04-16 18:37:55,243 [INFO] Loaded CIFAR10
2023-04-16 18:37:55,283 [INFO] Training indices read from params/train_idx.csv
2023-04-16 18:37:55,287 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 18:37:56,154 [INFO] Loaded VGG16 with default pretrained weights
2023-04-16 18:37:56,154 [INFO] Classifier modified to 10 classes
2023-04-16 18:38:03,090 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 18:38:03,091 [INFO] Loaded Cross Entropy Loss
2023-04-16 18:38:03,091 [INFO] Loaded LR scheduler
2023-04-16 18:38:03,988 [INFO] Read supporting modules base weights
2023-04-16 18:38:03,999 [INFO] Used supporting modules base weights
2023-04-16 18:38:03,999 [INFO] Training on 43750 samples
2023-04-16 18:40:10,325 [INFO] Sub epoch 0 train acc: 75.61 train loss: 0.0119 val acc: 81.49 val loss: 0.0046
2023-04-16 18:40:10,325 [INFO] Saving best model with val_acc: 81.488
2023-04-16 18:41:54,067 [INFO] Sub epoch 1 train acc: 83.54 train loss: 0.0086 val acc: 84.83 val loss: 0.0040
2023-04-16 18:41:54,068 [INFO] Saving best model with val_acc: 84.832
2023-04-16 18:43:38,043 [INFO] Sub epoch 2 train acc: 86.90 train loss: 0.0072 val acc: 85.33 val loss: 0.0039
2023-04-16 18:43:38,043 [INFO] Saving best model with val_acc: 85.328
2023-04-16 18:45:22,209 [INFO] Sub epoch 3 train acc: 89.11 train loss: 0.0063 val acc: 85.34 val loss: 0.0040
2023-04-16 18:45:22,209 [INFO] Saving best model with val_acc: 85.344
2023-04-16 18:47:05,913 [INFO] Sub epoch 4 train acc: 90.10 train loss: 0.0058 val acc: 85.84 val loss: 0.0040
2023-04-16 18:47:05,913 [INFO] Saving best model with val_acc: 85.84
2023-04-16 18:48:55,040 [INFO] Sub epoch 5 train acc: 91.49 train loss: 0.0053 val acc: 86.53 val loss: 0.0042
2023-04-16 18:48:55,041 [INFO] Saving best model with val_acc: 86.528
2023-04-16 18:50:42,503 [INFO] Sub epoch 6 train acc: 92.22 train loss: 0.0049 val acc: 86.66 val loss: 0.0044
2023-04-16 18:50:42,503 [INFO] Saving best model with val_acc: 86.656
2023-04-16 18:52:27,741 [INFO] Sub epoch 7 train acc: 92.97 train loss: 0.0045 val acc: 85.65 val loss: 0.0045
2023-04-16 18:54:10,931 [INFO] Sub epoch 8 train acc: 92.86 train loss: 0.0047 val acc: 86.64 val loss: 0.0049
2023-04-16 18:55:54,072 [INFO] Sub epoch 9 train acc: 93.52 train loss: 0.0043 val acc: 85.87 val loss: 0.0054
2023-04-16 18:57:37,303 [INFO] Sub epoch 10 train acc: 94.11 train loss: 0.0041 val acc: 86.51 val loss: 0.0052
2023-04-16 18:59:20,392 [INFO] Sub epoch 11 train acc: 94.62 train loss: 0.0037 val acc: 86.82 val loss: 0.0052
2023-04-16 18:59:20,393 [INFO] Saving best model with val_acc: 86.816
2023-04-16 19:01:04,733 [INFO] Sub epoch 12 train acc: 95.09 train loss: 0.0036 val acc: 86.02 val loss: 0.0055
2023-04-16 19:02:47,777 [INFO] Sub epoch 13 train acc: 95.36 train loss: 0.0036 val acc: 86.22 val loss: 0.0059
2023-04-16 19:04:30,922 [INFO] Sub epoch 14 train acc: 96.76 train loss: 0.0022 val acc: 87.36 val loss: 0.0053
2023-04-16 19:04:30,922 [INFO] Saving best model with val_acc: 87.36
2023-04-16 19:06:14,633 [INFO] Sub epoch 15 train acc: 97.57 train loss: 0.0016 val acc: 87.46 val loss: 0.0054
2023-04-16 19:06:14,633 [INFO] Saving best model with val_acc: 87.456
2023-04-16 19:07:58,594 [INFO] Sub epoch 16 train acc: 98.02 train loss: 0.0013 val acc: 87.79 val loss: 0.0055
2023-04-16 19:07:58,594 [INFO] Saving best model with val_acc: 87.792
2023-04-16 19:09:41,786 [INFO] Sub epoch 17 train acc: 98.23 train loss: 0.0011 val acc: 87.76 val loss: 0.0059
2023-04-16 19:11:24,671 [INFO] Sub epoch 18 train acc: 98.37 train loss: 0.0010 val acc: 87.98 val loss: 0.0058
2023-04-16 19:11:24,672 [INFO] Saving best model with val_acc: 87.984
2023-04-16 19:13:08,256 [INFO] Sub epoch 19 train acc: 98.56 train loss: 0.0009 val acc: 87.95 val loss: 0.0062
2023-04-16 19:14:50,837 [INFO] Sub epoch 20 train acc: 98.71 train loss: 0.0008 val acc: 87.89 val loss: 0.0062
2023-04-16 19:16:33,422 [INFO] Sub epoch 21 train acc: 98.83 train loss: 0.0008 val acc: 87.97 val loss: 0.0066
2023-04-16 19:18:16,020 [INFO] Sub epoch 22 train acc: 98.85 train loss: 0.0008 val acc: 88.13 val loss: 0.0063
2023-04-16 19:18:16,021 [INFO] Saving best model with val_acc: 88.128
2023-04-16 19:19:59,300 [INFO] Sub epoch 23 train acc: 98.97 train loss: 0.0007 val acc: 87.81 val loss: 0.0064
2023-04-16 19:21:42,145 [INFO] Sub epoch 24 train acc: 99.03 train loss: 0.0006 val acc: 88.08 val loss: 0.0065
2023-04-16 19:23:24,711 [INFO] Sub epoch 25 train acc: 99.07 train loss: 0.0006 val acc: 88.05 val loss: 0.0066
2023-04-16 19:25:07,286 [INFO] Sub epoch 26 train acc: 99.11 train loss: 0.0005 val acc: 88.06 val loss: 0.0066
2023-04-16 19:26:49,851 [INFO] Sub epoch 27 train acc: 99.11 train loss: 0.0006 val acc: 88.08 val loss: 0.0066
2023-04-16 19:28:32,463 [INFO] Sub epoch 28 train acc: 99.07 train loss: 0.0006 val acc: 88.13 val loss: 0.0067
2023-04-16 19:30:15,034 [INFO] Sub epoch 29 train acc: 99.15 train loss: 0.0005 val acc: 88.14 val loss: 0.0067
2023-04-16 19:30:15,034 [INFO] Saving best model with val_acc: 88.144
2023-04-16 19:31:58,302 [INFO] Sub epoch 30 train acc: 99.20 train loss: 0.0006 val acc: 88.18 val loss: 0.0067
2023-04-16 19:31:58,302 [INFO] Saving best model with val_acc: 88.176
2023-04-16 19:33:41,516 [INFO] Sub epoch 31 train acc: 99.26 train loss: 0.0005 val acc: 88.21 val loss: 0.0067
2023-04-16 19:33:41,516 [INFO] Saving best model with val_acc: 88.208
2023-04-16 19:35:24,807 [INFO] Sub epoch 32 train acc: 99.16 train loss: 0.0005 val acc: 88.18 val loss: 0.0068
2023-04-16 19:37:07,344 [INFO] Sub epoch 33 train acc: 99.24 train loss: 0.0005 val acc: 88.18 val loss: 0.0068
2023-04-16 19:38:49,882 [INFO] Sub epoch 34 train acc: 99.23 train loss: 0.0005 val acc: 88.22 val loss: 0.0068
2023-04-16 19:38:49,882 [INFO] Saving best model with val_acc: 88.224
2023-04-16 19:40:33,337 [INFO] Sub epoch 35 train acc: 99.25 train loss: 0.0005 val acc: 88.22 val loss: 0.0069
2023-04-16 19:42:16,042 [INFO] Sub epoch 36 train acc: 99.24 train loss: 0.0005 val acc: 88.22 val loss: 0.0069
2023-04-16 19:43:58,994 [INFO] Sub epoch 37 train acc: 99.19 train loss: 0.0005 val acc: 88.22 val loss: 0.0069
2023-04-16 19:45:43,455 [INFO] Sub epoch 38 train acc: 99.27 train loss: 0.0005 val acc: 88.22 val loss: 0.0069
2023-04-16 19:47:27,367 [INFO] Sub epoch 39 train acc: 99.24 train loss: 0.0004 val acc: 88.22 val loss: 0.0069
2023-04-16 19:49:13,181 [INFO] Sub epoch 40 train acc: 99.24 train loss: 0.0005 val acc: 88.22 val loss: 0.0069
2023-04-16 19:50:57,653 [INFO] Sub epoch 41 train acc: 99.24 train loss: 0.0005 val acc: 88.24 val loss: 0.0069
2023-04-16 19:50:57,653 [INFO] Saving best model with val_acc: 88.24
2023-04-16 19:54:07,717 [INFO] Training started
2023-04-16 19:54:07,731 [INFO] Using cuda
2023-04-16 19:54:09,600 [INFO] Loaded CIFAR10
2023-04-16 19:54:09,644 [INFO] Training indices read from params/train_idx.csv
2023-04-16 19:54:09,688 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 19:54:10,226 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 19:54:10,227 [INFO] Classifier modified to 10 classes
2023-04-16 19:54:17,167 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 19:54:17,167 [INFO] Loaded Cross Entropy Loss
2023-04-16 19:54:17,167 [INFO] Loaded LR scheduler
2023-04-16 19:54:17,587 [INFO] Read supporting modules base weights
2023-04-16 19:54:17,613 [INFO] Used supporting modules base weights
2023-04-16 19:54:17,613 [INFO] Training on 43750 samples
2023-04-16 19:57:31,318 [INFO] Sub epoch 0 train acc: 62.13 train loss: 0.0185 val acc: 71.15 val loss: 0.0067
2023-04-16 19:57:31,331 [INFO] Saving best model with val_acc: 71.152
2023-04-16 19:58:46,715 [INFO] Training started
2023-04-16 19:58:46,851 [INFO] Using cuda
2023-04-16 19:58:48,452 [INFO] Loaded CIFAR10
2023-04-16 19:58:48,477 [INFO] Training indices read from params/train_idx.csv
2023-04-16 19:58:48,480 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 19:58:48,938 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 19:58:48,940 [INFO] Classifier modified to 10 classes
2023-04-16 19:58:53,214 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 19:58:53,214 [INFO] Loaded Cross Entropy Loss
2023-04-16 19:58:53,214 [INFO] Loaded LR scheduler
2023-04-16 19:58:53,455 [INFO] Read supporting modules base weights
2023-04-16 19:58:53,481 [INFO] Used supporting modules base weights
2023-04-16 19:58:53,482 [INFO] Training on 43750 samples
2023-04-16 20:03:06,702 [INFO] Training started
2023-04-16 20:03:06,825 [INFO] Using cuda
2023-04-16 20:03:08,780 [INFO] Loaded CIFAR10
2023-04-16 20:03:08,810 [INFO] Training indices read from params/train_idx.csv
2023-04-16 20:03:08,815 [INFO] Validation indices read from params/val_idx.csv
2023-04-16 20:03:09,267 [INFO] Loaded EfficientNet V2 S with default pretrained weights
2023-04-16 20:03:09,269 [INFO] Classifier modified to 10 classes
2023-04-16 20:03:15,001 [INFO] Loaded optimizer ADAM with default parameters
2023-04-16 20:03:15,002 [INFO] Loaded Cross Entropy Loss
2023-04-16 20:03:15,002 [INFO] Loaded LR scheduler
2023-04-16 20:03:15,268 [INFO] Read supporting modules base weights
2023-04-16 20:03:15,298 [INFO] Used supporting modules base weights
2023-04-16 20:03:15,299 [INFO] Training on 43750 samples
2023-04-16 20:06:33,705 [INFO] Sub epoch 0 train acc: 62.01 train loss: 0.0185 val acc: 70.82 val loss: 0.0068
2023-04-16 20:06:33,716 [INFO] Saving best model with val_acc: 70.816
2023-04-16 20:09:22,435 [INFO] Sub epoch 1 train acc: 67.77 train loss: 0.0149 val acc: 72.75 val loss: 0.0062
2023-04-16 20:09:22,435 [INFO] Saving best model with val_acc: 72.752
2023-04-16 20:12:09,925 [INFO] Sub epoch 2 train acc: 68.50 train loss: 0.0144 val acc: 73.33 val loss: 0.0061
2023-04-16 20:12:09,925 [INFO] Saving best model with val_acc: 73.328
2023-04-16 20:14:56,918 [INFO] Sub epoch 3 train acc: 69.00 train loss: 0.0141 val acc: 74.19 val loss: 0.0059
2023-04-16 20:14:56,919 [INFO] Saving best model with val_acc: 74.192
2023-04-16 20:17:43,892 [INFO] Sub epoch 4 train acc: 69.08 train loss: 0.0140 val acc: 74.53 val loss: 0.0058
2023-04-16 20:17:43,893 [INFO] Saving best model with val_acc: 74.528
